# Lecture 18

CJA 2016-11-9

## Different Architectures

### Intel Xeon Phi Coprocessor architecture

Many Int*** core (MIC) Architecture

#### multicore vs. manycore

* Multicore: duo core, 4-core, upto 20-core
* Manycore: Intel Xeon Phi Coprocessor, 60 cores, trade-off
* 60 cores, in-order, low power
* Like "60-processor network", access like "ssh" into the cores

Knights Corner Architecture

* Best way to optimize code: Instruction re-ordering

Both **Accelerators** and **CPUs** have their own memory and are very efficient, but fetching data between them (through the PCI-bus) is extremely slow.

Knights Landing (KNL) Architecture

* Core & VPU
* Cache Mode: throw out LRU (least recently used) data

### GPU (graphical processing unit)

* SIMD machines
* Each core on a GPU card is called a "thread"
* GPGPU (General Purpose GPU)
* Best situation to use GPU: no much movement of data, but operates a lot on those data
    1. Data copied from CPU memory to GPU memory (DRAM)
    2. CPU tells the GPU threads what instructions to execute
    3. When done, GPU data copied back out to CPU memory

#### OpenACC Directives

* add directive `#pragma acc kernels` before for-loop
* compiler will compile the loop as kernel (NVIDIA purchased the Portland Group and adapt the compilers `pgcc` to compile code for their products)
  `pgcc -acc -ta=nvidia -Minfo=accel -o saxpy_acc saxpy.c`
    
##### Note for GPU on Flux

* Use `-l node=1:gpu=1` to request a compute node with GPU
* `module load cuda` (load the cuda library that allows for GPU programming)
* `deviceQuery` command displays info about the GPU card
    * "Total amount of global memory"
* Control data copying (because it's slow)
    * At the beginning of loop
      `#pragm acc data copy(dataWannaCopy), create(variableWannaCreate)`
    * When need `#pragma acc update host(dataWannaCopyBack)`
* For high computational intensity tasks, this is much more efficient than OpenMP
    
    
    
    
    
Q1: when a[m][n], is it in L1 cache?  
Q2: when "malloc", is it in L1 cache?